{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \r\n",
    "\r\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\r\n",
    "\r\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \r\n",
    "\r\n",
    "**План выполнения проекта**\r\n",
    "\r\n",
    "1. Загрузить и подготовьте данные. Убрать лишние символы в текстах, провести лемматизацию, удалить стоп-слова.\r\n",
    "2. Обучите модели LogisticRegression и LightGBM. \r\n",
    "3. Выбрать модель с лучшей метриков F1 и проверить ее на тестовой выборке.\r\n",
    "\r\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\r\n",
    "\r\n",
    "**Описание данных**\r\n",
    "\r\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages (from lightgbm) (1.8.0)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.3 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0\n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7  Your vandalism to the Matt Shirvington article...      0\n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9  alignment on this subject and which are contra...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "\n",
    "df.info()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, toxic]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text']=='']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записей с пустыми комментариями нет. Подготовим тексты для преобразования их в векторный вид:\r\n",
    "- приведем тексты к нижнему регистру; \r\n",
    "- уберем лишние символы, оставив только слова;\r\n",
    "- преобразуем текст в токены;\r\n",
    "- лемматизируем;\r\n",
    "- уберем стопслова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_comments(text):\n",
    "    text = text.lower()\n",
    "    text = remove_waste_symbols(text)\n",
    "    tokens = tokenize(text)\n",
    "    tokens = lemmatize(tokens)\n",
    "    tokens = remove_stop_words(tokens)\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def remove_waste_symbols(text):\n",
    "    return re.sub('[^a-z ]+', ' ', text)\n",
    "                  \n",
    "def tokenize(text):\n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    stop_words = stopwords.words('english')\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wondered sect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              tokens  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestion improvement wondered sect...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = df['text'].apply(lambda x: prepare_comments(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Успешно провели первичную подготовку текста, очистив от символов, стоп слов и проведя лемматизацию.\r\n",
    "\r\n",
    "Следующий шаг - разделим данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['tokens'], df['toxic'], test_size=.2, random_state=12345, stratify=df['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последнее, что надо сделать перед обучением модели - преобразуем текст в векторное представление. Будем использовать TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\r\n",
    "Обучим модели логистической регрессии и градиентного бустинга и выберем модель с лучшей метрикой f1_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5; 1/6] START C=0.1, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/6] END ........................C=0.1, max_iter=10; total time=   0.4s\n",
      "[CV 2/5; 1/6] START C=0.1, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 1/6] END ........................C=0.1, max_iter=10; total time=   0.5s\n",
      "[CV 3/5; 1/6] START C=0.1, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/6] END ........................C=0.1, max_iter=10; total time=   0.5s\n",
      "[CV 4/5; 1/6] START C=0.1, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 1/6] END ........................C=0.1, max_iter=10; total time=   0.5s\n",
      "[CV 5/5; 1/6] START C=0.1, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 1/6] END ........................C=0.1, max_iter=10; total time=   0.3s\n",
      "[CV 1/5; 2/6] START C=0.1, max_iter=100.........................................\n",
      "[CV 1/5; 2/6] END .......................C=0.1, max_iter=100; total time=   1.7s\n",
      "[CV 2/5; 2/6] START C=0.1, max_iter=100.........................................\n",
      "[CV 2/5; 2/6] END .......................C=0.1, max_iter=100; total time=   1.9s\n",
      "[CV 3/5; 2/6] START C=0.1, max_iter=100.........................................\n",
      "[CV 3/5; 2/6] END .......................C=0.1, max_iter=100; total time=   1.6s\n",
      "[CV 4/5; 2/6] START C=0.1, max_iter=100.........................................\n",
      "[CV 4/5; 2/6] END .......................C=0.1, max_iter=100; total time=   1.9s\n",
      "[CV 5/5; 2/6] START C=0.1, max_iter=100.........................................\n",
      "[CV 5/5; 2/6] END .......................C=0.1, max_iter=100; total time=   1.8s\n",
      "[CV 1/5; 3/6] START C=1.0, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 3/6] END ........................C=1.0, max_iter=10; total time=   0.4s\n",
      "[CV 2/5; 3/6] START C=1.0, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 3/6] END ........................C=1.0, max_iter=10; total time=   0.5s\n",
      "[CV 3/5; 3/6] START C=1.0, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 3/6] END ........................C=1.0, max_iter=10; total time=   0.5s\n",
      "[CV 4/5; 3/6] START C=1.0, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 3/6] END ........................C=1.0, max_iter=10; total time=   0.5s\n",
      "[CV 5/5; 3/6] START C=1.0, max_iter=10..........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 3/6] END ........................C=1.0, max_iter=10; total time=   0.4s\n",
      "[CV 1/5; 4/6] START C=1.0, max_iter=100.........................................\n",
      "[CV 1/5; 4/6] END .......................C=1.0, max_iter=100; total time=   3.0s\n",
      "[CV 2/5; 4/6] START C=1.0, max_iter=100.........................................\n",
      "[CV 2/5; 4/6] END .......................C=1.0, max_iter=100; total time=   2.9s\n",
      "[CV 3/5; 4/6] START C=1.0, max_iter=100.........................................\n",
      "[CV 3/5; 4/6] END .......................C=1.0, max_iter=100; total time=   3.0s\n",
      "[CV 4/5; 4/6] START C=1.0, max_iter=100.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 4/6] END .......................C=1.0, max_iter=100; total time=   3.4s\n",
      "[CV 5/5; 4/6] START C=1.0, max_iter=100.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 4/6] END .......................C=1.0, max_iter=100; total time=   3.5s\n",
      "[CV 1/5; 5/6] START C=10.0, max_iter=10.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 5/6] END .......................C=10.0, max_iter=10; total time=   0.5s\n",
      "[CV 2/5; 5/6] START C=10.0, max_iter=10.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 5/6] END .......................C=10.0, max_iter=10; total time=   0.3s\n",
      "[CV 3/5; 5/6] START C=10.0, max_iter=10.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 5/6] END .......................C=10.0, max_iter=10; total time=   0.5s\n",
      "[CV 4/5; 5/6] START C=10.0, max_iter=10.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 5/6] END .......................C=10.0, max_iter=10; total time=   0.5s\n",
      "[CV 5/5; 5/6] START C=10.0, max_iter=10.........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 5/6] END .......................C=10.0, max_iter=10; total time=   0.3s\n",
      "[CV 1/5; 6/6] START C=10.0, max_iter=100........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/6] END ......................C=10.0, max_iter=100; total time=   3.4s\n",
      "[CV 2/5; 6/6] START C=10.0, max_iter=100........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/6] END ......................C=10.0, max_iter=100; total time=   3.5s\n",
      "[CV 3/5; 6/6] START C=10.0, max_iter=100........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 6/6] END ......................C=10.0, max_iter=100; total time=   3.3s\n",
      "[CV 4/5; 6/6] START C=10.0, max_iter=100........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 6/6] END ......................C=10.0, max_iter=100; total time=   3.4s\n",
      "[CV 5/5; 6/6] START C=10.0, max_iter=100........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 6/6] END ......................C=10.0, max_iter=100; total time=   3.3s\n",
      "{'C': 10.0, 'max_iter': 100}\n",
      "0.7615712241225763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\anaconda3\\envs\\praktikum\\envs\\ds_practicum_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "params_logreg = {\n",
    "    'max_iter': [10, 100],\n",
    "    'C':[0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "f1_logreg = make_scorer(f1_score)\n",
    "\n",
    "model_logreg = GridSearchCV(LogisticRegression(random_state=12345), param_grid=params_logreg, scoring=f1_logreg, verbose=10)\n",
    "model_logreg.fit(x_train, y_train)\n",
    "\n",
    "best_params_logreg = model_logreg.best_params_\n",
    "best_f1_logreg = model_logreg.best_score_\n",
    "\n",
    "print(best_params_logreg)\n",
    "print(best_f1_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression показала f1_score = 0.76 на кроссвалидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START boosting_type=gbdt..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.966833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509318\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9669\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[CV 1/5; 1/3] END ........................boosting_type=gbdt; total time=  21.0s\n",
      "[CV 2/5; 1/3] START boosting_type=gbdt..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.159934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510260\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9682\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[CV 2/5; 1/3] END ........................boosting_type=gbdt; total time=  22.1s\n",
      "[CV 3/5; 1/3] START boosting_type=gbdt..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.288551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512010\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9716\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[CV 3/5; 1/3] END ........................boosting_type=gbdt; total time=  22.0s\n",
      "[CV 4/5; 1/3] START boosting_type=gbdt..........................................\n",
      "[LightGBM] [Info] Number of positive: 10360, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.101232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 512057\n",
      "[LightGBM] [Info] Number of data points in the train set: 101947, number of used features: 9735\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101621 -> initscore=-2.179337\n",
      "[LightGBM] [Info] Start training from score -2.179337\n",
      "[CV 4/5; 1/3] END ........................boosting_type=gbdt; total time=  21.2s\n",
      "[CV 5/5; 1/3] START boosting_type=gbdt..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91588\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.051801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509562\n",
      "[LightGBM] [Info] Number of data points in the train set: 101947, number of used features: 9693\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101612 -> initscore=-2.179445\n",
      "[LightGBM] [Info] Start training from score -2.179445\n",
      "[CV 5/5; 1/3] END ........................boosting_type=gbdt; total time=  22.1s\n",
      "[CV 1/5; 2/3] START boosting_type=dart..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.310931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509318\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9669\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[CV 1/5; 2/3] END ........................boosting_type=dart; total time=  24.0s\n",
      "[CV 2/5; 2/3] START boosting_type=dart..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.020085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510260\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9682\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[CV 2/5; 2/3] END ........................boosting_type=dart; total time=  23.5s\n",
      "[CV 3/5; 2/3] START boosting_type=dart..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.329320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 512010\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9716\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[CV 3/5; 2/3] END ........................boosting_type=dart; total time=  22.8s\n",
      "[CV 4/5; 2/3] START boosting_type=dart..........................................\n",
      "[LightGBM] [Info] Number of positive: 10360, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.384383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512057\n",
      "[LightGBM] [Info] Number of data points in the train set: 101947, number of used features: 9735\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101621 -> initscore=-2.179337\n",
      "[LightGBM] [Info] Start training from score -2.179337\n",
      "[CV 4/5; 2/3] END ........................boosting_type=dart; total time=  23.1s\n",
      "[CV 5/5; 2/3] START boosting_type=dart..........................................\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91588\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.100749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509562\n",
      "[LightGBM] [Info] Number of data points in the train set: 101947, number of used features: 9693\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101612 -> initscore=-2.179445\n",
      "[LightGBM] [Info] Start training from score -2.179445\n",
      "[CV 5/5; 2/3] END ........................boosting_type=dart; total time=  22.5s\n",
      "[CV 1/5; 3/3] START boosting_type=goss..........................................\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.080510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509318\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9669\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV 1/5; 3/3] END ........................boosting_type=goss; total time=  24.1s\n",
      "[CV 2/5; 3/3] START boosting_type=goss..........................................\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.381511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510260\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9682\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV 2/5; 3/3] END ........................boosting_type=goss; total time=  25.6s\n",
      "[CV 3/5; 3/3] START boosting_type=goss..........................................\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.379658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 512010\n",
      "[LightGBM] [Info] Number of data points in the train set: 101946, number of used features: 9716\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101613 -> initscore=-2.179434\n",
      "[LightGBM] [Info] Start training from score -2.179434\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV 3/5; 3/3] END ........................boosting_type=goss; total time=  24.5s\n",
      "[CV 4/5; 3/3] START boosting_type=goss..........................................\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 10360, number of negative: 91587\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.380804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 512057\n",
      "[LightGBM] [Info] Number of data points in the train set: 101947, number of used features: 9735\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101621 -> initscore=-2.179337\n",
      "[LightGBM] [Info] Start training from score -2.179337\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV 4/5; 3/3] END ........................boosting_type=goss; total time=  24.5s\n",
      "[CV 5/5; 3/3] START boosting_type=goss..........................................\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 10359, number of negative: 91588\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 1.258798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 509562\n",
      "[LightGBM] [Info] Number of data points in the train set: 101947, number of used features: 9693\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101612 -> initscore=-2.179445\n",
      "[LightGBM] [Info] Start training from score -2.179445\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[CV 5/5; 3/3] END ........................boosting_type=goss; total time=  24.1s\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Warning] Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss.To suppress this warning, set data_sample_strategy=goss instead.\n",
      "[LightGBM] [Info] Number of positive: 12949, number of negative: 114484\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.631927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 602094\n",
      "[LightGBM] [Info] Number of data points in the train set: 127433, number of used features: 11113\n",
      "[LightGBM] [Info] Using GOSS\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101614 -> initscore=-2.179417\n",
      "[LightGBM] [Info] Start training from score -2.179417\n",
      "{'boosting_type': 'goss'}\n",
      "0.7454879842121203\n"
     ]
    }
   ],
   "source": [
    "params_lgbm = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "}\n",
    "\n",
    "f1_lgbm = make_scorer(f1_score)\n",
    "\n",
    "model_lgbm = GridSearchCV(\n",
    "    LGBMClassifier(random_state=12345),\n",
    "    param_grid=params_lgbm,\n",
    "    scoring=f1_lgbm,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "model_lgbm.fit(x_train, y_train)\n",
    "\n",
    "best_params_lgbm = model_lgbm.best_params_\n",
    "best_f1_lgbm = model_lgbm.best_score_\n",
    "\n",
    "print(best_params_lgbm)\n",
    "print(best_f1_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGBMClassifier показала f1_score = 0.75 на кроссвалидации.\n",
    "\n",
    "Лучшая метрика F1-score у модели LogisticRegression. Проверим значение метрики на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on test for LogisticRegression: 0.7801709401709402\n"
     ]
    }
   ],
   "source": [
    "best_model_logreg = LogisticRegression(random_state=12345, C=best_params_logreg['C'], max_iter=best_params_logreg['max_iter'])\n",
    "\n",
    "best_model_logreg.fit(x_train, y_train)\n",
    "\n",
    "predictions = best_model_logreg.predict(x_test)\n",
    "f1_test = f1_score(y_test, predictions)\n",
    "\n",
    "print('f1_score on test for LogisticRegression:', f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках работы:\n",
    "- была проведена подготовка текста - очистка от символов, лемматизаций, удаление стоп-слов;\n",
    "- тексты преобразованы в векторы с использованием TfidfVectorizer;\n",
    "- обучены модели LogisticRegression и LightGBM;\n",
    "- LogisticRegression показал f1_score = 0.76 на кроссвалидации;\n",
    "- LightGBM показал f1_score = 0.75 на кроссвалидации;\n",
    "- Лучшая модель LogisticRegression показала f1_score = 0.78 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 474,
    "start_time": "2024-02-09T14:21:09.242Z"
   },
   {
    "duration": 3329,
    "start_time": "2024-02-09T14:21:28.685Z"
   },
   {
    "duration": 2457,
    "start_time": "2024-02-09T14:22:25.728Z"
   },
   {
    "duration": 1489,
    "start_time": "2024-02-09T14:23:34.199Z"
   },
   {
    "duration": 1222,
    "start_time": "2024-02-09T14:23:43.386Z"
   },
   {
    "duration": 865,
    "start_time": "2024-02-09T14:24:26.875Z"
   },
   {
    "duration": 73,
    "start_time": "2024-02-09T14:25:12.151Z"
   },
   {
    "duration": 26,
    "start_time": "2024-02-09T14:25:17.697Z"
   },
   {
    "duration": 10,
    "start_time": "2024-02-09T16:20:47.883Z"
   },
   {
    "duration": 7,
    "start_time": "2024-02-09T16:22:31.705Z"
   },
   {
    "duration": 1244,
    "start_time": "2024-02-09T16:23:09.036Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T16:23:24.554Z"
   },
   {
    "duration": 8,
    "start_time": "2024-02-09T16:25:44.503Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T16:25:51.924Z"
   },
   {
    "duration": 4189,
    "start_time": "2024-02-09T21:15:00.987Z"
   },
   {
    "duration": 2603,
    "start_time": "2024-02-09T21:15:07.135Z"
   },
   {
    "duration": 3,
    "start_time": "2024-02-09T21:15:22.906Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:15:44.757Z"
   },
   {
    "duration": 7,
    "start_time": "2024-02-09T21:15:56.173Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:16:01.874Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T21:16:59.119Z"
   },
   {
    "duration": 7,
    "start_time": "2024-02-09T21:29:37.099Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T21:29:45.927Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T21:31:26.075Z"
   },
   {
    "duration": 735,
    "start_time": "2024-02-09T21:33:07.514Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T21:33:22.960Z"
   },
   {
    "duration": 119543,
    "start_time": "2024-02-09T21:33:23.921Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-09T21:37:25.136Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:37:42.322Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:38:21.490Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:38:22.889Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:38:45.775Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-09T21:38:47.296Z"
   },
   {
    "duration": 80,
    "start_time": "2024-02-09T21:52:55.253Z"
   },
   {
    "duration": 25,
    "start_time": "2024-02-09T21:54:11.702Z"
   },
   {
    "duration": 7,
    "start_time": "2024-02-09T21:54:29.975Z"
   },
   {
    "duration": 7,
    "start_time": "2024-02-09T21:54:49.097Z"
   },
   {
    "duration": 633,
    "start_time": "2024-02-09T21:56:33.530Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T21:56:55.683Z"
   },
   {
    "duration": 20,
    "start_time": "2024-02-09T21:57:06.030Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T21:57:11.988Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T21:57:55.496Z"
   },
   {
    "duration": 118024,
    "start_time": "2024-02-09T21:57:57.985Z"
   },
   {
    "duration": 136,
    "start_time": "2024-02-09T22:12:19.656Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-09T22:12:21.304Z"
   },
   {
    "duration": 5625,
    "start_time": "2024-02-09T22:12:24.528Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T22:18:45.646Z"
   },
   {
    "duration": 6,
    "start_time": "2024-02-09T22:18:57.188Z"
   },
   {
    "duration": 5,
    "start_time": "2024-02-09T22:19:41.655Z"
   },
   {
    "duration": 22,
    "start_time": "2024-02-09T22:22:48.273Z"
   },
   {
    "duration": 1323924,
    "start_time": "2024-02-09T22:22:54.771Z"
   },
   {
    "duration": 0,
    "start_time": "2024-02-09T22:44:58.697Z"
   },
   {
    "duration": 19,
    "start_time": "2024-02-09T22:48:22.363Z"
   },
   {
    "duration": 4,
    "start_time": "2024-02-09T22:48:26.162Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
